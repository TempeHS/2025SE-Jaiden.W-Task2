{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../README.md)\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "This Jupyter Notepad is a selection of data engineering processes I applied to my  data before model training to maximise the performance of my machine learning model.\n",
    "\n",
    "#### Feature Engineering Process\n",
    "- Deriving new variables from existing ones\n",
    "    - Encoding categorical features\n",
    "    - Calculating new features from existing features\n",
    "- Combining features/feature interactions\n",
    "- Identifying the most relevant features for the model\n",
    "- Transforming Features\n",
    "  - [Dividing Data into categories](https://web.ma.utexas.edu/users/mks/statmistakes/dividingcontinuousintocategories.html)\n",
    "  - Mathematical transformations (for example logarithmic transformations). Logarithmic transformations are a powerful tool in the world of statistical analysis. They are often used to transform data that exhibit skewness or other irregularities, making it easier to analyze, visualize, and interpret the results.\n",
    "- Creating Domain-Specific Features that incorporating knowledge from the specific domain to create features that capture important characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deriving new variables from existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables\n",
    "\n",
    "Data Encoding converts textual data into numerical format, so that it can be used as input for algorithms to process. The reason for encoding is that most machine learning algorithms work with numbers and not with text or categorical variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'rating' column encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'PG', 'G', 'Not Rated', 'NC-17', 'Approved', 'TV-PG', 'PG-13',\n",
       "       'Unrated', 'X', 'TV-MA', 'TV-14'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rating\n",
      "0          8\n",
      "1          8\n",
      "2          2\n",
      "3          2\n",
      "4          8\n",
      "...      ...\n",
      "7569       5\n",
      "7570       8\n",
      "7571       6\n",
      "7572       8\n",
      "7573       5\n",
      "\n",
      "[7574 rows x 1 columns]\n",
      "{0: 'G', 1: 'TV-PG', 2: 'PG', 3: 'Approved', 4: 'Unrated', 5: 'Not Rated', 6: 'PG-13', 7: 'TV-14', 8: 'R', 9: 'TV-MA', 10: 'NC-17', 11: 'X'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Define the custom class order from least to most violent\n",
    "rating_order = ['G', 'TV-PG', 'PG', 'Approved', 'Unrated', 'Not Rated', 'PG-13', 'TV-14', 'R', 'TV-MA', 'NC-17', 'X']\n",
    "\n",
    "# Fit and transform the 'rating' column\n",
    "data_frame['rating'] = pd.Series(data_frame['rating'])\n",
    "\n",
    "# Map the 'rating' column to the custom order\n",
    "data_frame['rating'] = data_frame['rating'].map({rating: idx for idx, rating in enumerate(rating_order)})\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the encoding\n",
    "print(data_frame[['rating']])\n",
    "\n",
    "# Print the mapping of classes to labels\n",
    "print(dict(enumerate(rating_order)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'genre' column encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             name  rating  year  \\\n",
      "0                                     The Shining       8  1980   \n",
      "1                                 The Blue Lagoon       8  1980   \n",
      "2  Star Wars: Episode V - The Empire Strikes Back       2  1980   \n",
      "3                                       Airplane!       2  1980   \n",
      "4                                      Caddyshack       8  1980   \n",
      "\n",
      "        released     score     votes         director  \\\n",
      "0  June 13, 1980  0.878378  0.386241  Stanley Kubrick   \n",
      "1   July 2, 1980  0.527027  0.027069   Randal Kleiser   \n",
      "2  June 20, 1980  0.918919  0.499993   Irvin Kershner   \n",
      "3   July 2, 1980  0.783784  0.092070     Jim Abrahams   \n",
      "4  July 25, 1980  0.729730  0.044986     Harold Ramis   \n",
      "\n",
      "                    writer            star         country  ...  \\\n",
      "0             Stephen King  Jack Nicholson  United Kingdom  ...   \n",
      "1  Henry De Vere Stacpoole  Brooke Shields   United States  ...   \n",
      "2           Leigh Brackett     Mark Hamill   United States  ...   \n",
      "3             Jim Abrahams     Robert Hays   United States  ...   \n",
      "4       Brian Doyle-Murray     Chevy Chase   United States  ...   \n",
      "\n",
      "   genre_Fantasy  genre_Horror genre_Music  genre_Musical  genre_Mystery  \\\n",
      "0          False         False       False          False          False   \n",
      "1          False         False       False          False          False   \n",
      "2          False         False       False          False          False   \n",
      "3          False         False       False          False          False   \n",
      "4          False         False       False          False          False   \n",
      "\n",
      "   genre_Romance  genre_Sci-Fi  genre_Sport  genre_Thriller  genre_Western  \n",
      "0          False         False        False           False          False  \n",
      "1          False         False        False           False          False  \n",
      "2          False         False        False           False          False  \n",
      "3          False         False        False           False          False  \n",
      "4          False         False        False           False          False  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'genre' column\n",
    "data_frame = pd.get_dummies(data_frame, columns=['genre'])\n",
    "\n",
    "# Display the first few rows of the encoded dataframe\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'company' & 'country' column encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       company   country\n",
      "0     0.043966  0.106681\n",
      "1     0.043834  0.719039\n",
      "2     0.001320  0.719039\n",
      "3     0.042250  0.719039\n",
      "4     0.007922  0.719039\n",
      "...        ...       ...\n",
      "7569  0.000132  0.004621\n",
      "7570  0.000132  0.719039\n",
      "7571  0.000132  0.719039\n",
      "7572  0.000132  0.719039\n",
      "7573  0.000264  0.719039\n",
      "\n",
      "[7574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of each unique value in the 'company' column\n",
    "company_freq = data_frame['company'].value_counts() / len(data_frame)\n",
    "# Map the frequencies back to the original dataframe\n",
    "data_frame['company'] = data_frame['company'].map(company_freq)\n",
    "\n",
    "# Calculate the frequency of each unique value in the 'country' column\n",
    "country_freq = data_frame['country'].value_counts() / len(data_frame)\n",
    "# Map the frequencies back to the original dataframe\n",
    "data_frame['country'] = data_frame['country'].map(country_freq)\n",
    "\n",
    "#Print the results\n",
    "print(data_frame[['company', 'country']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert 'released' to a date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be worked on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining features/feature interactions\n",
    "\n",
    "While individual features can be powerful predictors, their interactions often carry even more information. Feature interaction engineering is the process of creating new features that represent the interaction between two or more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Budget x Revenue (BxR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BxR\n",
      "0     0.015670\n",
      "1     0.020412\n",
      "2     0.179987\n",
      "3     0.029025\n",
      "4     0.013763\n",
      "...        ...\n",
      "7569  0.132324\n",
      "7570  0.000001\n",
      "7571  0.000132\n",
      "7572  0.027744\n",
      "7573  0.000004\n",
      "\n",
      "[7574 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the budget-to-revenue ratio\n",
    "data_frame['BxR'] = data_frame['gross'] / (data_frame['budget'] + 1)  # Avoid division by zero\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data_frame[['BxR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Budget x Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      budget_per_vote\n",
      "0            0.038495\n",
      "1            0.012299\n",
      "2            0.033703\n",
      "3            0.008995\n",
      "4            0.016120\n",
      "...               ...\n",
      "7569         0.224370\n",
      "7570         0.100221\n",
      "7571         0.100309\n",
      "7572         0.000006\n",
      "7573         0.100302\n",
      "\n",
      "[7574 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the budget-to-vote ratio\n",
    "data_frame['budget_per_vote'] = data_frame['budget'] / (data_frame['votes'] + 1)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data_frame[['budget_per_vote']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Director & Star Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      director_popularity  star_popularity\n",
      "0                0.032788         0.536282\n",
      "1                0.069072         0.032608\n",
      "2                0.224599         0.355951\n",
      "3                0.194719         0.045201\n",
      "4                0.207334         0.226050\n",
      "...                   ...              ...\n",
      "7569             0.162059         0.162059\n",
      "7570             0.000001         0.000001\n",
      "7571             0.000145         0.000145\n",
      "7572             0.027744         0.027744\n",
      "7573             0.000005         0.000005\n",
      "\n",
      "[7574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Compute cumulative gross revenue for each director/star\n",
    "data_frame['director_popularity'] = data_frame.groupby('director')['gross'].transform('sum')\n",
    "data_frame['star_popularity'] = data_frame.groupby('star')['gross'].transform('sum')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data_frame[['director_popularity', 'star_popularity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Features\n",
    "\n",
    "Filtering is like applying the where clause in a database. It is widely used and can help when you need to work on a specific subset of your data. For our use case, let us filter the data to only include rows where the 'SEX' is 'Male'. There is no method call for this, we can just use conditional indexing to fulfil our purpose.\n",
    "\n",
    "In this, case some domain knowledge and data analysis have informed you that there is 'bimodality' in the data and males and females have a different trends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Domain-Specific Features\n",
    "\n",
    "Domain knowledge is about understanding the domain or subject area of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time Based Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"1981\" doesn't match format \"%B %d, %Y\", at position 108. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extracting month and quarter from release date\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_month\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreleased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[1;32m      3\u001b[0m data_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_quarter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreleased\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mquarter\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"1981\" doesn't match format \"%B %d, %Y\", at position 108. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "#to be worked on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled and engineered data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../Model_Training/model_ready_data2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
